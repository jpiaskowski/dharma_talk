---
format: 
  revealjs:
    theme: simple
    css: [custom.css, UI_theme.scss]
    embed-resources: true
    includes: 
      in-header: custom.html
editor: source
execute:
  echo: false
  message: false
  warning: false
---

```{r}
#| include: false
library(DHARMa); library(glmmTMB); library(performance); library(dplyr); library(lme4)

  #   includes:
  #     in-header: [custom.html, banner.js]
  # pdf:
  #   toc: true
  #   number-sections: true
  #   colorlinks: true
```


## Using Randomized Quantile Residuals to Assess Model Fit of Generalized Linear Mixed Models {background-color="#191919"}

<br> <br> 
*Julia Piaskowski*

*May 14, 2025* 
<br> <br> 
**https://some-link-to-talk.html**



## Linear Mixed Model

$$\mathbf{Y = Xb + Za + \epsilon} $$

$$\epsilon \sim N(0, \sigma^2 \mathbf{I_n}) $$
$$a \sim N(0, \sigma_a^2) $$

$$ y_i|z_i \simùëÅ(x_i \beta, \sigma^2/r_i) $$

::: notes
error terms 'iid'
no association between mean and variance
random terms normally distributed
:::

## Standard Residual Plots

```{r}
data(warpbreaks)
m1 <- lm(log(breaks) ~ wool*tension, data = warpbreaks)
check_model(m1, check = c("linearity", "qq"), detrend=FALSE, alpha=0)
```

::: notes
standard checks to verify the distribution
:::

## Standard Residuals {.smaller}

Raw
$$\epsilon_i = Y_i - \hat{Y_i} $$

(internally) Studentized:

$$\epsilon_i = \frac {Y_i - \hat{Y_i}} {\hat{s}}$$

Pearson/Scaled:

$$ \epsilon_i = \frac {Y_i - \hat{Y_i}} {sd(Y_i)}  $$


## GLMM Formulation (binomial example) {.smaller}

Dependent variable: $Y_{ij}$ (survived)

survival: $p_i = Y_i/N$

$$Y_{ij}|r_j \sim Binomial(N, \pi_{ij})$$

$$\eta_{ij} = \eta + \alpha_i + r_j$$
($\eta$ = mean, $\alpha_i$ = treatment, $r_j$ = grouping variable)

$$\eta_{ij} = log(\frac{\pi_{ij}} {1 - \pi_{ij}}  )$$

::: notes
Survival of insects after insecticide applications ($i^{th}$ treatment) across several different locations ($j^{th}$ random effect/hierarchal grouping). 
:::

## Raw Residuals from GLMMs Can Be Nonsensical

```{r}
data("VerbAgg")
m2 <- glmer(r2 ~ (Anger + Gender + btype + situ)^2 + (1|id) + (1|item), 
            family = binomial, data = VerbAgg, nAGQ=0L)
plot(m2)
```


## Raw/Scaled Residuals Can Lack Diagnostic Capabilities for GLMMs

* Visual patterns are difficult to interpret
* Over and under-dispersion are difficult to assess
* Goodness of fit tests are not valid

<center>
***Different distributional assumptions and mathematical mean/variance relationships of some distributions require a different approach***
</enter>

::: footer
**Exception:** log-linear models because the identity link function is used, thus $\mathbf{e} \sim N(0, \sigma^2) $

:::


::: {.r-stack background-color="#FDDC5C"}
# The Original Quantile Residuals
:::


## Background

For $y_1,...,y_n$ responses:  

$$y_i \sim \mathcal{P}(\mu_i, \phi)$$

CDF: $$F(y; \mu, \phi)$$ 

For a continuous $F$, $F(y_i; \mu_i \phi)$ are uniformly distributed, and the quantile residuals are:

$$ r_{i} = \Phi^{-1} \left\{F(y_i; \hat{\mu_i}, \hat{\phi} )\right\}$$

::: notes
r converges to a normal distribution when parameters are 'consistently' estimated

Probit (inverse of normal dist) \Phi(x) returns a probability p, and \Phi^{-1}(p) returns the z-score
:::

::: footer
Dunn KP, and GK Smyth (1996). Randomized quantile residuals. *Journal of Computational and Graphical Statistics* 5, 1-10.
:::

## Example: Survival Times of Patients

Survival: $y_i \sim Exp(\mu_i)$

$$ \text{log }\mu_i =  \beta_0 + \beta_1 \text{ log } x_i  $$

Quantile residuals:

$$ r_{i} = \Phi^{-1} \left\{  1-exp(y_i/\hat{\mu_i}) \right\}$$

## Discontinuous CDF, *F*

$$r_i = \Phi^{-1}(u_i)$$
$$ u_i \sim Uniform(a_i, b_j]$$
$$a_i = lim_{y \uparrow y_i} F(y; \hat{\mu_i}, \hat{\phi})$$

$$ b_i = F(y_i; \hat{\mu_i}, \hat{\phi})  $$

::: notes
a_i = Pr(Y < y_i)
b_i = Pr(Y <= y_i)

(a, b]

very small space, u is sampled from that space (uniform dist)
:::



## Binomial Example {.smaller}

$$y_i \sim binomial(n, p_i) $$

$$ \text{logit} (p_i) = \beta_0 + \beta_1x_i $$
$$r_i = \Phi^{-1}(u_i)$$

$$ u_i \sim Uniform(a_i, b_j] $$

$$a_i = lim_{y \uparrow y_i} F(y; n, \hat{p_i}) =\displaystyle\sum_{i=0}^{\lfloor k-1 \rfloor} \begin{pmatrix}
  n \\
  i
\end{pmatrix} p_i(1-p)^{n-i}$$


$$b_i = F(y_i; n, \hat{p_i}) =\displaystyle\sum_{i=0}^{\lfloor k \rfloor} \begin{pmatrix}
  n \\
  i
\end{pmatrix} p_i(1-p)^{n-i}$$


## Method implemented in 'statmod'

<img src="images/statmod_pkg.png" class="outlined-shadow-image" alt="Your Image">


## This Method Has Been Around

<img src="images/statmod.png" class="outlined-shadow-image" alt="Your Image">


::: footer
First submitted to CRAN in February, 2003. 
:::

::: notes
since at least 2003
functions available for many distributions: binomial, Poisson, neg bin, gamma, tweedie
:::


----------------------------------

> Randomization is used to produce continuously distributed residuals when the response is discrete or has a discrete component. This means that the quantile residuals will vary from one realization to another for a given data set and fitted model.


::: {.right-align}
#### *--Smythe & Dunn (1996)*
:::

::: notes
They recommend drawing at least 4 quantile samples per observation
:::


::: {.r-stack background-color="#FDDC5C"}
# DHARMa

**(Diagnostics for HierArchical Regression Models)**

:::

## The DHARMa Process

1. Model something using a generalized linear model with a chosen distribution and link function. 


$$\mathbf{Y = X\beta+Za}$$
$$ \mathbf{Y|a\sim G(\mu, R)} $$
linear predictor: $\mathbf{\eta = X\beta}$

fitted value: $E(Y) = \mu$

Link function: $\eta = g(\mu)$

::: notes
"G" is generalized term denoting any distribution with shape and scale parameters
:::


## The DHARMa Process {.smaller}

*For each observation in the data set:*

2. Simulate new observations using fitted value as the mean and model parameters (e.g. shape, scale) for the other distributional parameters.

$$ Y_i \sim G(\hat{\mu_i}, \hat{\phi}) $$

3. Calculate the quantile for the cumulative distribution function 

$$ r_{i} = F(y_i; \hat{\mu_i}, \hat{\phi} )$$



::: notes
This can even include Gaussian processes
Can do this for different categorical variables and in some cases, for different random effects
:::

## Expectations of the Quantile Residuals

$$ r_{ij} \sim Uniform(0,1) $$


$ r_{ij} = 0$:  everything is larger    
$ r_{ij} = 1$:  everything is smaller   
$ r_{ij} = 0.5$:  right in the middle   


DHARMa runs 250 simulations (per observation) by default, they recommend up to 1000


## Poisson Example

$$ (\hat{Y_i} = \lambda = 5,; \quad Y_i = 7 )$$
```{r}
par(mar = c(5.1, 5, 2.1, 2.1), mfrow = c(1, 2))

yi = 7; mu = 5
x <- rpois(500, mu)
dat = as.data.frame(table(x)) |> 
  mutate(x = as.integer(x),
         tot = cumsum(Freq)) |> 
  mutate(dens = tot/sum(Freq))

res = filter(dat, x == yi) |> pull(dens)  

hist(x, main = NULL, freq = FALSE, 
     xlab = expression(paste("simulated values for ", hat(Y[i]))),
     ylab = "Density", col = "#AFE4DE")
abline(v = yi + .5, lwd = 2, lty = 2)

plot(dat$x, dat$dens, col = "red2", lty = 1, 
     xlab = expression(paste("simulated values for ", hat(Y[i]))), 
     ylab = "Cumulative Density", type = "l", lwd = 1.5) 

lines(x = c(yi,yi), y = c(0, res), lwd = 2, lty = 2)
lines(x = c(0,yi), y = c(res, res), lwd = 2, lty = 2)
text(8, 0.4, expression(paste(Y[i])))
text(4, 0.8, expression(paste(r[i])))
```
1.	For a sample size of 150 per group, cohen's D = 0.5 and alpha = 0.05, the power is 0.99
## Quantile Residuals for 1 Observation

```{r}
# generate multiple simulations to see
res_sim <- function(mu = 5, yi = 7) {
  x1 <- rpois(500, mu)
  dat1 = as.data.frame(table(x1)) |> 
    mutate(x = as.integer(x1),
           tot = cumsum(Freq)) |> 
    mutate(dens = tot/sum(Freq))
  
  filter(dat1, x1 == yi) |> pull(dens) 
  }

#res_sim(mu = 5, yi = 7)

sims <- replicate(500, res_sim())

```

```{r}
par(mfrow = c(1, 1))

hist(sims, main = expression(paste("Poisson Example: ", hat(Y[i]), " = ", lambda, " = 5, ", 
                                   Y[i], " = 7")),
     xlab = "Sample Quantiles (200 simulations of 500 obs each)", col = "#AFE4DE")
abline(v = mean(sims), lwd = 2, lty = 2, col = "red2")
```

## Poisson GLMM Example

Create a data set with a random effect ("group", 10 levels), a covariate ("Enviroinment1") and a Poisson-distributed response variable ("observedResponse"): 

```{r, echo=TRUE}
testData = createData(sampleSize = 500)
```

Analyze correctly and incorrectly:

```{r, echo=TRUE}
rightModel <- glmer(observedResponse ~ Environment1 + (1|group) , 
                     family = "poisson", data = testData)

wrongModel <- lmer(observedResponse ~ Environment1 + (1|group) , 
                     data = testData)
```


## 'Standard' Residuals

```{r}
par(mfrow = c(1, 2))

plot(fitted(rightModel), residuals(rightModel, type = "deviance"), main = "correct family", xlab = "fitted", ylab = "deviance residuals", col = "#5E48FF")
plot(fitted(wrongModel), residuals(wrongModel, type = "pearson"), main = "incorrect family", xlab = "fitted", ylab = "Pearson residuals", col = "#5E48FF")
```

## Quantile Residuals
*Correctly Specified Model*

```{r}
sr <- simulateResiduals(rightModel, plot = TRUE)
```

::: notes
- Kolmogorov-Smirnov test (`ks.test()`, `punif()`) against a uniform distribution (0, 1)
- disperion test:
- outlier test (2-sided by default): "DHARMa residuals are created by simulating from the fitted model, and comparing the simulated values to the observed data. It can occur that all simulated values are higher or smaller than the observed data, in which case they get the residual value of 0 and 1, respectively" --- these are DHARMa 'outliers'. No info on magnitude of these. Outlier test uses the binomial test (`binom.test()`) of the number of outliers relative to the data set size and the prob is set as 1/(nSim +1) (so P decreases an nsim increases). Other optons for integer dists w/ n<500 run a bootstrap: manually calculate how often an obs is outlier in an data set compared to in a bootstrap
- quantile tests: fits splines (`qgam::qgam()`) at 0.25, 0.5 and 0.75 quantiles and looks for deviations from the expectation of a flat line, does a BH adjustment
:::

## Quantile Residuals
*Incorrectly Specified Model*


```{r}
swr <- simulateResiduals(wrongModel, plot = TRUE)
```

## Distributions of Quantile Residuals

```{r}
par(mfrow = c(1, 2))
hist(sr, main = "correctly specified model", xlab = "quantile residuals")
hist(swr, main = "incorrectly specified model", xlab = "quantile residuals")
```

## Quantile Function of the Standard Normal Distribution

```{r}
par(mfrow = c(1, 2))
qres1 <- qnorm(residuals(sr))
hist(qres1, main = "Correctly Specified Model", col = "#AFE4DE", xlab = "Randomized Quantile Residuals")
qres2 <- qnorm(residuals(swr))
hist(qres2, main = "Incorrectly Specified Model", col = "#AFE4DE", xlab = "Randomized Quantile Residuals")
```


## Notes on DHARMa Implementation

- It depends on the simulation functions build into GLMM package (supported packages: lme4, glmmTMB, ...)
- Commonly, only the last stochastic level (e.g. Poisson) is simulated, conditional on the fitted random effects - basically an omnibus test
- Residuals can be simulated for individuals predictors and tests can be conducted for individual factors
- for any kind of autocorrelation, conditional simulations are a must so that plots don't indicate patterns or the tests fail due to autocorrelation


::: notes
from DHARMa::simulateResiduals(): If the model is correctly specified, the simulated residuals should be flat regardless how many hierarchical levels we re-simulate. The most thorough procedure would therefore be to test all possible options. If testing only one option, I would recommend to re-simulate all levels, because this essentially tests the model structure as a whole. This is the default setting in the DHARMa package. A potential drawback is that re-simulating the lower-level random effects creates more variability, which may reduce power for detecting problems in the upper-level stochastic processes. In particular dispersion tests may produce different results when switching from conditional to unconditional simulations, and often the conditional simulation is more sensitive.
:::

## Conditional and Marginal Models

**In Progress**

(focus on lme4::glmer() and glmmTMB)

## Other Functionality 

*(Implemented in DHARMa)* 


* Uniformity test
* Quantile location tesy
* Outlier test
* Tests for spatial and temporal autocorrelation 
* Test for zero-inflation
* Over/Under dispersion tests

::: notes
wildly, the outlier test is a 2-sided test. Are there enough outliers?
:::

## Best Practices

- Use quantile residuals because they are a better diagnostic feature for checking model fit
- Many of the tests are quite useful (but, as always, don't rely on absolute threshold)
- Outlier test results should be treated with caution
-  **RTFM**: read the DHARMa vignette; it is very helpful!
- ....More


## Sources {.smaller}

Bates DM, Maechler M, Bolker BM and S Walker (2015). "Fitting Linear Mixed-Effects Models Using lme4." *Journal of Statistical Software*, 67(1), 1-48. doi:10.18637/jss.v067.i01.
  
Brooks ME, Kristensen K, van Benthem KJ, Magnusson A, Berg CW, Nielsen A, Skaug HJ, Maechler M and BM Bolker (2017). "glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling." *The R Journal*, 9(2), 378-400. doi: 10.32614/RJ-2017-066.

Dunn KP, and GK Smyth (1996). Randomized quantile residuals. *Journal of Computational and Graphical Statistics* 5, 1-10.

Feng et al (2017). Randomized quantile residuals: an omnibus model diagnostic tool with unified reference distribution. *arXiv* <https://doi.org/10.48550/arXiv.1708.08527>

## Sources {.smaller}

Gelman A and J Hill (2007). *Data Analysis Using Regression and Multilevel/Hierarchical Models*. Cambridge University Press, New York.

Hartig F (2022). DHARMa: Residual Diagnostics for Hierarchical (Multi-Level/Mixed) Regression Models. R package version 0.4.6, <https://CRAN.R-project.org/package=DHARMa>.

Pinheiro JC and DM Bates (2000). *Mixed-Effects Models in S and S-PLUS*. Springer Verlag, New York.

Stroup WW, Ptukhina M and J Garai (2024). *Generalize Linear Mixed Models: Modern Concepts, Methods and Applications*. CRC Press, Boca Raton. 


## 

<br>

> (G)LMMs are hard - harder than you may think based on what you may have learned in your second statistics class....

::: {.right-align}
#### *--Ben Bolker, [GLMM FAQ](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html)*
:::
